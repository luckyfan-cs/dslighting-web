import{_ as e,c as t,o as r,ag as o}from"./chunks/framework.BHzxCEDw.js";const c=JSON.parse('{"title":"配置说明","description":"","frontmatter":{},"headers":[],"relativePath":"guide/configuration.md","filePath":"guide/configuration.md"}'),i={name:"guide/configuration.md"};function l(n,a,h,p,s,u){return r(),t("div",null,[...a[0]||(a[0]=[o('<h1 id="配置说明" tabindex="-1">配置说明 <a class="header-anchor" href="#配置说明" aria-label="Permalink to &quot;配置说明&quot;">​</a></h1><p>DSLighting 通过配置文件和环境变量进行灵活配置。</p><h2 id="环境变量配置" tabindex="-1">环境变量配置 <a class="header-anchor" href="#环境变量配置" aria-label="Permalink to &quot;环境变量配置&quot;">​</a></h2><p>在项目根目录创建 `.env` 文件：</p><p>```bash</p><h1 id="llm-api-配置" tabindex="-1">LLM API 配置 <a class="header-anchor" href="#llm-api-配置" aria-label="Permalink to &quot;LLM API 配置&quot;">​</a></h1><p>API_KEY=your_api_key_here API_BASE=<a href="https://api.openai.com/v1" target="_blank" rel="noreferrer">https://api.openai.com/v1</a></p><h1 id="或使用多模型配置" tabindex="-1">或使用多模型配置 <a class="header-anchor" href="#或使用多模型配置" aria-label="Permalink to &quot;或使用多模型配置&quot;">​</a></h1><p>LLM_MODEL_CONFIGS=[{&quot;model&quot;: &quot;gpt-4&quot;, &quot;api_key&quot;: &quot;key1&quot;, &quot;api_base&quot;: &quot;base1&quot;}]</p><h1 id="其他配置" tabindex="-1">其他配置 <a class="header-anchor" href="#其他配置" aria-label="Permalink to &quot;其他配置&quot;">​</a></h1><p>LOG_PATH=runs/benchmark_results MAX_WORKERS=4 ```</p><h2 id="llm-提供商配置" tabindex="-1">LLM 提供商配置 <a class="header-anchor" href="#llm-提供商配置" aria-label="Permalink to &quot;LLM 提供商配置&quot;">​</a></h2><h3 id="openai" tabindex="-1">OpenAI <a class="header-anchor" href="#openai" aria-label="Permalink to &quot;OpenAI&quot;">​</a></h3><p>```bash API_KEY=sk-xxx API_BASE=<a href="https://api.openai.com/v1" target="_blank" rel="noreferrer">https://api.openai.com/v1</a> ```</p><h3 id="智谱ai-推荐" tabindex="-1">智谱AI (推荐) <a class="header-anchor" href="#智谱ai-推荐" aria-label="Permalink to &quot;智谱AI (推荐)&quot;">​</a></h3><p>```bash API_KEY=your_zhipu_api_key API_BASE=<a href="https://open.bigmodel.cn/api/paas/v4" target="_blank" rel="noreferrer">https://open.bigmodel.cn/api/paas/v4</a> ```</p><h3 id="硅基流动" tabindex="-1">硅基流动 <a class="header-anchor" href="#硅基流动" aria-label="Permalink to &quot;硅基流动&quot;">​</a></h3><p>```bash API_KEY=your_siliconflow_api_key API_BASE=<a href="https://api.siliconflow.cn/v1" target="_blank" rel="noreferrer">https://api.siliconflow.cn/v1</a> ```</p><h2 id="config-yaml-配置" tabindex="-1">config.yaml 配置 <a class="header-anchor" href="#config-yaml-配置" aria-label="Permalink to &quot;config.yaml 配置&quot;">​</a></h2><p>主配置文件 `config.yaml` 包含以下部分：</p><h3 id="competitions-配置" tabindex="-1">Competitions 配置 <a class="header-anchor" href="#competitions-配置" aria-label="Permalink to &quot;Competitions 配置&quot;">​</a></h3><p>```yaml competitions:</p><ul><li>bike-sharing-demand</li><li>titanic</li><li>house-prices ```</li></ul><h3 id="模型定价配置" tabindex="-1">模型定价配置 <a class="header-anchor" href="#模型定价配置" aria-label="Permalink to &quot;模型定价配置&quot;">​</a></h3><p>```yaml custom_model_pricing: gpt-4: input: 0.03 output: 0.06 gpt-3.5-turbo: input: 0.0015 output: 0.002 ```</p><h3 id="日志配置" tabindex="-1">日志配置 <a class="header-anchor" href="#日志配置" aria-label="Permalink to &quot;日志配置&quot;">​</a></h3><p>```yaml run: log_artifacts: true log_traces: true save_code: true ```</p><h2 id="工作流配置" tabindex="-1">工作流配置 <a class="header-anchor" href="#工作流配置" aria-label="Permalink to &quot;工作流配置&quot;">​</a></h2><p>每个工作流都可以有独立的配置：</p><h3 id="aide-配置" tabindex="-1">AIDE 配置 <a class="header-anchor" href="#aide-配置" aria-label="Permalink to &quot;AIDE 配置&quot;">​</a></h3><p>```yaml aide: max_iterations: 10 temperature: 0.7 review_threshold: 0.8 ```</p><h3 id="dsagent-配置" tabindex="-1">DSAgent 配置 <a class="header-anchor" href="#dsagent-配置" aria-label="Permalink to &quot;DSAgent 配置&quot;">​</a></h3><p>```yaml dsagent: max_steps: 20 planning_iterations: 3 execution_timeout: 300 ```</p><h2 id="运行时参数" tabindex="-1">运行时参数 <a class="header-anchor" href="#运行时参数" aria-label="Permalink to &quot;运行时参数&quot;">​</a></h2><p>通过命令行参数覆盖配置：</p><p>```bash python run_benchmark.py \\ --workflow aide \\ --llm-model gpt-4 \\ --temperature 0.8 \\ --max-iterations 15 ```</p><h2 id="web-ui-配置" tabindex="-1">Web UI 配置 <a class="header-anchor" href="#web-ui-配置" aria-label="Permalink to &quot;Web UI 配置&quot;">​</a></h2><p>Web UI 的配置文件位于 `web_ui/backend/.env`：</p><p>```bash</p><h1 id="后端配置" tabindex="-1">后端配置 <a class="header-anchor" href="#后端配置" aria-label="Permalink to &quot;后端配置&quot;">​</a></h1><p>BACKEND_HOST=0.0.0.0 BACKEND_PORT=8003 CORS_ORIGINS=<a href="http://localhost:3000" target="_blank" rel="noreferrer">http://localhost:3000</a></p><h1 id="前端配置" tabindex="-1">前端配置 <a class="header-anchor" href="#前端配置" aria-label="Permalink to &quot;前端配置&quot;">​</a></h1><p>NEXT_PUBLIC_API_URL=<a href="http://localhost:8003" target="_blank" rel="noreferrer">http://localhost:8003</a> ```</p><p>查看<a href="/dslighting/guide/faq.html">常见问题</a>解决配置问题。</p>',44)])])}const m=e(i,[["render",l]]);export{c as __pageData,m as default};
